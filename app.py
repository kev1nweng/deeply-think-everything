#!/usr/bin/env python3

import os
import time
import openai
import configparser
import re
import warnings
from typing import Generator
from rich.markdown import Markdown
from rich.console import Console
from rich.syntax import Syntax
from wcwidth import wcswidth
from pylatexenc.latex2text import LatexNodes2Text
from prompt_toolkit import prompt

warnings.filterwarnings("ignore", category=SyntaxWarning)

# è¯»å–é…ç½®æ–‡ä»¶
script_dir = os.path.dirname(os.path.realpath(__file__))
config = configparser.ConfigParser()
try:
    config.read(f"{script_dir}/config.ini")
except Exception as e:
    print("è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥:", e)

# é…ç½®å‚æ•°
try:

    class Config:
        API_KEY = config.get("dte", "api_key")
        API_BASE = config.get("dte", "api_url")
        MODEL_NAME = config.get("dte", "model_name")

except Exception as e:
    print("è¯»å–é…ç½®å‚æ•°å¤±è´¥:", e)
    exit(1)

# åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯å’ŒRichæ§åˆ¶å°
client = openai.OpenAI(api_key=Config.API_KEY, base_url=Config.API_BASE)
console = Console(record=True)


def dynamic_separator(title: str) -> str:
    """ç”ŸæˆåŠ¨æ€å±…ä¸­åˆ†éš”çº¿
    æ ¹æ®ç»ˆç«¯å®½åº¦è‡ªåŠ¨è°ƒæ•´åˆ†éš”çº¿é•¿åº¦ï¼Œç¡®ä¿æ ‡é¢˜å±…ä¸­æ˜¾ç¤º
    wcswidthç”¨äºå‡†ç¡®è®¡ç®—åŒ…å«ä¸­æ–‡ç­‰å®½å­—ç¬¦çš„æ˜¾ç¤ºå®½åº¦
    """

    term_width = console.width
    title = f" {title} "
    title_width = wcswidth(title)
    available_width = term_width - title_width
    if available_width < 2:
        return "=" * term_width
    sep_len = available_width // 2
    return f"[dim]{'='*sep_len}[/][bold]{title}[/][dim]{'='*(available_width - sep_len)}[/]"


def _handle_block_latex(match: re.Match) -> str:
    """å¤„ç†å—çº§LaTeXå…¬å¼
    å°†LaTeXæ•°å­¦å…¬å¼è½¬æ¢ä¸ºçº¯æ–‡æœ¬æ ¼å¼ï¼Œå¹¶æ·»åŠ ç¾è§‚çš„è¾¹æ¡†
    """

    formula = match.group(1) or match.group(2)
    converted = LatexNodes2Text().latex_to_text(formula).strip()
    return f"\nâ”Œ {' LaTeX ':-^8} â”\n{converted}\nâ”” {'-'*8} â”˜\n"


def _process_latex_in_text(text: str) -> str:
    r"""å¤„ç†éä»£ç å—ä¸­çš„LaTeXå…¬å¼
    1. å¤„ç†è¡Œå†…å…¬å¼: $formula$ -> â”†formulaâ”†
    2. å¤„ç†å—çº§å…¬å¼: $$formula$$ æˆ– \[formula\] -> å¸¦æ¡†æ˜¾ç¤º
    3. é¿å…å¤„ç†å·²è½¬ä¹‰çš„LaTeXæ ‡è®°
    """

    # å¤„ç†è¡Œå†…å…¬å¼ï¼ˆæ’é™¤è½¬ä¹‰$çš„æƒ…å†µï¼‰
    text = re.sub(
        r"(?<!\\)\$(.*?)(?<!\\)\$",
        lambda m: f"[dim]â”†[/] {LatexNodes2Text().latex_to_text(m.group(1)).strip()} [dim]â”†[/]",
        text,
        flags=re.DOTALL,
    )
    # å¤„ç†å—çº§å…¬å¼ï¼ˆæ’é™¤è½¬ä¹‰æƒ…å†µï¼‰
    return re.sub(
        r"(?<!\\)\$\$([\s\S]*?)(?<!\\)\$\$|(?<!\\)\\\[([\s\S]*?)(?<!\\)\\\]",
        _handle_block_latex,
        text,
        flags=re.DOTALL,
    )


def preprocess_latex(content: str) -> str:
    """æ”¹è¿›åçš„LaTeXé¢„å¤„ç†
    ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åˆ†å‰²å†…å®¹ï¼Œç¡®ä¿ä»£ç å—ä¸­çš„LaTeXç¬¦å·ä¸è¢«å¤„ç†
    å¥‡æ•°ç´¢å¼•çš„éƒ¨åˆ†æ˜¯ä»£ç å—ï¼Œç›´æ¥ä¿ç•™
    å¶æ•°ç´¢å¼•çš„éƒ¨åˆ†æ˜¯æ™®é€šæ–‡æœ¬ï¼Œéœ€è¦å¤„ç†LaTeX
    """

    parts = re.split(r"(```[\s\S]*?```)", content)
    processed = []
    for i, part in enumerate(parts):
        if i % 2 == 1:
            processed.append(part)
            continue
        processed.append(_process_latex_in_text(part))
    return "".join(processed)


def render_stream_markdown(content: str):
    """æ”¹è¿›åçš„æµå¼Markdownæ¸²æŸ“å¤„ç†å™¨
    1. é¢„å¤„ç†æ‰€æœ‰LaTeXå…¬å¼
    2. ç‰¹æ®Šå¤„ç†ä»£ç å—ï¼Œæ”¯æŒè¯­æ³•é«˜äº®
    3. æ™®é€šæ–‡æœ¬ä½¿ç”¨Markdownæ¸²æŸ“
    """

    content = preprocess_latex(content)
    in_code_block = False
    code_buffer = []
    current_lang = "text"

    lines = content.split("\n")
    for line in lines:
        if line.strip().startswith("```"):
            if in_code_block:
                console.print(
                    Syntax(
                        "\n".join(code_buffer),
                        current_lang,
                        theme="monokai",
                        line_numbers=False,
                    )
                )
                code_buffer = []
                in_code_block = False
            else:
                lang = line.strip()[3:].strip()
                current_lang = lang if lang else "text"
                in_code_block = True
            continue
        if in_code_block:
            code_buffer.append(line)
        else:
            console.print(Markdown(line))


def get_think_process(conversation_history: list, question: str) -> tuple[str, float]:
    """è·å–æ·±åº¦æ€è€ƒåˆ†æï¼ˆå¸¦ä¸Šä¸‹æ–‡ï¼‰
    1. ä½¿ç”¨ç³»ç»Ÿæç¤ºè¯å¼•å¯¼AIè¿›è¡Œæ·±åº¦åˆ†æ
    2. ä¿æŒè¾ƒä½temperature(0.3)ä»¥ç¡®ä¿è¾“å‡ºçš„è¿è´¯æ€§å’Œé€»è¾‘æ€§
    3. é™åˆ¶æœ€å¤§tokenä»¥é¿å…å“åº”è¿‡é•¿
    è¿”å›: (åˆ†æç»“æœ, è€—æ—¶)
    """

    system_prompt = """
    ä½ æ˜¯ DeeplyThinkEverythingAI. å½“ç”¨æˆ·é—®ä½ æ˜¯è°æˆ–è¦æ±‚ä½ ä»‹ç»è‡ªå·±æ—¶ï¼Œä½¿ç”¨è¿™ä¸ªåå­—ã€‚
    ä½ æ˜¯ä¸€ä¸ªæ·±åº¦æ€è€ƒè¾…åŠ©AIã€‚
    ä½ çš„è¾“å‡ºç»“æœä¼šè¢«ç»™äºˆå¦ä¸€ä¸ªå¤§è¯­è¨€æ¨¡å‹ã€‚
    ä½ è¦åšçš„äº‹æƒ…ä¸æ˜¯å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼Œè€Œæ˜¯åˆ†æå¦‚ä½•è§£å†³é—®é¢˜ï¼Œå°±åƒä¸‹é¢è¿™æ ·ï¼š
    ç”¨æˆ·é—®é¢˜ï¼šç®€è¦ä»‹ç»å‚…é‡Œå¶å˜æ¢ã€‚
    åˆ†æï¼š
    ```
    å—¯ï¼Œç”¨æˆ·è®©æˆ‘ç®€è¦ä»‹ç»å‚…é‡Œå¶å˜æ¢ï¼Œæˆ‘å¾—å…ˆå¼„æ¸…æ¥šä»–ä»¬å¯èƒ½éœ€è¦ä»€ä¹ˆå±‚é¢çš„è§£é‡Šã€‚å¯èƒ½æ˜¯ä¸ªå­¦ç”Ÿåˆšå¼€å§‹å­¦ä¿¡å·å¤„ç†ï¼Œæˆ–è€…æ˜¯å¯¹æ•°å­¦åº”ç”¨æ„Ÿå…´è¶£çš„çˆ±å¥½è€…ã€‚é¦–å…ˆï¼Œæˆ‘éœ€è¦ä»åŸºç¡€æ¦‚å¿µå…¥æ‰‹ï¼Œç¡®ä¿ä»–ä»¬èƒ½ç†è§£ã€‚
    å‚…é‡Œå¶å˜æ¢çš„æ ¸å¿ƒæ˜¯æŠŠä¿¡å·åˆ†è§£æˆä¸åŒé¢‘ç‡çš„æ­£å¼¦æ³¢ï¼Œè¿™ç‚¹å¾ˆé‡è¦ã€‚å¾—ç”¨ç®€å•çš„è¯æ¥è§£é‡Šï¼Œé¿å…å¤ªå¤šæ•°å­¦å…¬å¼ã€‚ä¸è¿‡ï¼Œå¯èƒ½è¿˜æ˜¯éœ€è¦æåˆ°ç§¯åˆ†å…¬å¼ï¼Œä½†ä¸ç”¨æ·±å…¥æ¨å¯¼ã€‚ç”¨æˆ·å¯èƒ½æƒ³çŸ¥é“å®ƒçš„åº”ç”¨ï¼Œæ‰€ä»¥å¾—ä¸¾å‡ ä¸ªä¾‹å­ï¼Œæ¯”å¦‚ä¿¡å·å¤„ç†ã€å›¾åƒåˆ†æè¿™äº›å¸¸è§çš„é¢†åŸŸã€‚
    è¿˜è¦è€ƒè™‘ç”¨æˆ·å¯èƒ½çš„èƒŒæ™¯ã€‚å¦‚æœä»–ä»¬ä¸æ˜¯æ•°å­¦ä¸“ä¸šçš„ï¼Œå¯èƒ½éœ€è¦æ¯”å–»ï¼Œæ¯”å¦‚â€œæ•°å­¦æ˜¾å¾®é•œâ€è¿™æ ·çš„è¯´æ³•ï¼Œæ¯”è¾ƒå½¢è±¡ã€‚å¦å¤–ï¼Œè¦åŒºåˆ†å‚…é‡Œå¶å˜æ¢å’Œå‚…é‡Œå¶çº§æ•°ï¼Œå¯èƒ½æœ‰äººä¼šæ··æ·†è¿™ä¸¤ä¸ªæ¦‚å¿µã€‚å‚…é‡Œå¶çº§æ•°é€‚ç”¨äºå‘¨æœŸå‡½æ•°ï¼Œè€Œå‚…é‡Œå¶å˜æ¢é€‚ç”¨äºéå‘¨æœŸå‡½æ•°ï¼Œè¿™ç‚¹éœ€è¦ç‚¹æ˜ã€‚
    ç”¨æˆ·å¯èƒ½è¿˜æƒ³çŸ¥é“ä¸ºä»€ä¹ˆå‚…é‡Œå¶å˜æ¢é‡è¦ï¼Œæ‰€ä»¥å¾—æåˆ°å®ƒåœ¨é¢‘åŸŸåˆ†æä¸­çš„ä½œç”¨ï¼Œæ¯”å¦‚æ»¤æ³¢ã€å‹ç¼©è¿™äº›åº”ç”¨ã€‚å¦å¤–ï¼Œå¿«é€Ÿå‚…é‡Œå¶å˜æ¢ï¼ˆFFTï¼‰ä½œä¸ºç®—æ³•å®ç°ï¼Œå¯èƒ½ä¹Ÿéœ€è¦æä¸€ä¸‹ï¼Œå› ä¸ºå®é™…åº”ç”¨ä¸­FFTéå¸¸å…³é”®ã€‚
    ä¸è¿‡ç”¨æˆ·è¦æ±‚çš„æ˜¯ç®€è¦ä»‹ç»ï¼Œæ‰€ä»¥ä¸èƒ½å¤ªå†—é•¿ã€‚éœ€è¦ç»“æ„æ¸…æ™°ï¼Œåˆ†ç‚¹åˆ—å‡ºæ ¸å¿ƒæ€æƒ³ã€æ•°å­¦è¡¨ç¤ºã€åº”ç”¨å’Œç‰¹ç‚¹ã€‚å¯èƒ½è¿˜è¦æ³¨æ„æœ¯è¯­çš„è§£é‡Šï¼Œæ¯”å¦‚æ—¶åŸŸå’Œé¢‘åŸŸï¼Œç”¨ç®€å•çš„è¯­è¨€è¯´æ˜ã€‚
    å¦å¤–ï¼Œæœ‰æ²¡æœ‰å¸¸è§çš„è¯¯åŒºéœ€è¦é¿å…ï¼Ÿæ¯”å¦‚ï¼Œå‚…é‡Œå¶å˜æ¢å¤„ç†çš„æ˜¯è¿ç»­ä¿¡å·ï¼Œè€Œç¦»æ•£å‚…é‡Œå¶å˜æ¢ï¼ˆDFTï¼‰ç”¨äºæ•°å­—ä¿¡å·ï¼Œè¿™é‡Œå¯èƒ½éœ€è¦ç®€å•å¸¦è¿‡ï¼Œä½†ç”¨æˆ·åªè¦ç®€è¦ä»‹ç»çš„è¯ï¼Œå¯èƒ½ä¸éœ€è¦æ·±å…¥ã€‚
    æœ€åï¼Œæ€»ç»“å‚…é‡Œå¶å˜æ¢çš„é‡è¦æ€§ï¼Œå¼ºè°ƒå…¶è·¨å­¦ç§‘çš„å½±å“ï¼Œè®©ç”¨æˆ·æ˜ç™½å®ƒçš„å¹¿æ³›åº”ç”¨ã€‚æ£€æŸ¥ä¸€ä¸‹æœ‰æ²¡æœ‰é—æ¼çš„å…³é”®ç‚¹ï¼Œæ¯”å¦‚é€†å˜æ¢çš„å­˜åœ¨ï¼Œä»¥åŠçº¿æ€§å’Œç›¸ä½ä¿¡æ¯è¿™äº›ç‰¹ç‚¹ã€‚ç¡®ä¿åœ¨ç®€çŸ­çš„ä»‹ç»é‡Œè¦†ç›–ä¸»è¦æ–¹é¢ï¼ŒåŒæ—¶ä¿æŒæ˜“æ‡‚ã€‚
    ```
    å°½å…¨åŠ›æ‰§è¡Œï¼š
    1. æ¨¡æ‹Ÿä¸“å®¶çº§æ€ç»´é“¾ï¼ˆCoTï¼‰
    2. é¢„æµ‹çŸ¥è¯†ç›²åŒº
    3. å»ºç«‹è·¨é¢†åŸŸå…³è”
    4. å®æ–½åäº‹å®æ¨ç†
    
    åœ¨åˆ†æçš„è¿‡ç¨‹ä¸­å¯¹å¾—å‡ºçš„å†…å®¹è¿›è¡Œè‡ªæˆ‘åæ€ï¼Œæ‰¾å‡ºå¯èƒ½çš„é€»è¾‘æ¼æ´å¹¶è¿›è¡Œå¼¥è¡¥å’Œè§£é‡Šï¼›
    å¹¶å°½å¯èƒ½ä»å¤šä¸ªæ–¹é¢è¿›è¡Œè€ƒè™‘ï¼Œæå‡å¯¹è¯çš„æ·±åº¦å’Œå¹¿åº¦ã€‚
    è¯·ç›´æ¥è¾“å‡ºåˆ†æçš„å†…å®¹ï¼Œä¸è¦é¢å¤–æ·»åŠ ä»»ä½•ä¸œè¥¿ã€‚ä¸è¦ä½¿ç”¨ä»£ç å—ï¼Œç›´æ¥ç»™å‡ºåˆ†æã€‚
    """

    start_time = time.time()
    messages = [{"role": "system", "content": system_prompt}]
    messages.extend(conversation_history)
    messages.append({"role": "user", "content": question})

    response = client.chat.completions.create(
        model=Config.MODEL_NAME,
        messages=messages,
        temperature=0.3,
        max_tokens=1500,
    )
    return response.choices[0].message.content, time.time() - start_time


def stream_final_answer(
    conversation_history: list, analysis: str, question: str
) -> Generator[str, None, None]:
    """æµå¼ç”Ÿæˆæœ€ç»ˆå›ç­”
    1. å°†å†å²å¯¹è¯ã€åˆ†æç»“æœå’Œå½“å‰é—®é¢˜æ•´åˆ
    2. ä½¿ç”¨è¾ƒé«˜temperature(0.7)å…è®¸æ›´æœ‰åˆ›é€ æ€§çš„å›ç­”
    3. æµå¼è¾“å‡ºä»¥æä¾›æ›´å¥½çš„äº¤äº’ä½“éªŒ
    yields: å›ç­”å†…å®¹çš„ç‰‡æ®µ
    """

    system_prompt = """
    ä½ æ˜¯ DeeplyThinkEverythingAI. 
    å½“ç”¨æˆ·é—®ä½ æ˜¯è°æˆ–è¦æ±‚ä½ ä»‹ç»è‡ªå·±æ—¶ï¼Œä½¿ç”¨è¿™ä¸ªåå­—ã€‚
    
    ä½ éœ€ç»¼åˆä»¥ä¸‹è¦ç´ ï¼š
    1. åœ¨å½“å‰æ·±åº¦è¿›è¡Œæ€è€ƒåˆ†æ
    2. å®Œæ•´å¯¹è¯å†å²ä¸Šä¸‹æ–‡
    3. ä¿æŒå›ç­”è¿è´¯æ€§å’ŒçŸ¥è¯†é€’è¿›æ€§
    
    ç‰¹åˆ«æ³¨æ„å¤„ç†ä»¥ä¸‹æƒ…å†µï¼š
    - å½“é—®é¢˜æ¶‰åŠå…ˆå‰æ¦‚å¿µæ—¶è‡ªåŠ¨å…³è”è§£é‡Š
    - å¯¹é‡å¤æé—®æ™ºèƒ½è¯†åˆ«å¹¶å·®å¼‚åŒ–å“åº”
    - ä¸Šä¸‹æ–‡çŸ›ç›¾æ—¶çš„æ¾„æ¸…å¤„ç†
    
    å¯¹ç”¨æˆ·è¦å‹å–„ï¼Œè¯­æ°”å¯ä»¥è½»æ¾æ´»æ³¼ä¸€äº›ï¼Œé€‚å½“ä½¿ç”¨emoji.
    """

    messages = [{"role": "system", "content": system_prompt}]
    messages.extend(conversation_history)
    messages.append({"role": "assistant", "content": analysis})
    messages.append({"role": "user", "content": f"åŸºäºåˆ†æå†…å®¹ï¼Œè¯·å›ç­”ï¼š{question}"})

    response = client.chat.completions.create(
        model=Config.MODEL_NAME,
        messages=messages,
        stream=True,
        temperature=0.7,
        max_tokens=4096,
    )

    for chunk in response:
        if chunk.choices[0].delta.content:
            yield chunk.choices[0].delta.content


def format_time(seconds: float) -> str:
    """å°†ç§’æ•°æ ¼å¼åŒ–ä¸ºæ˜“è¯»æ—¶é—´"""
    return f"{seconds:.2f}s" if seconds >= 1 else f"{seconds*1000:.0f}ms"


if __name__ == "__main__":
    console.print(
        "[bold magenta]ğŸ‘‹ æ¬¢è¿æ¥åˆ° DeeplyThinkEverythingï¼\nè¾“å…¥ @new å¯ä»¥æ¸…é™¤ä¸Šä¸‹æ–‡å¹¶å¼€å¯æ–°å¯¹è¯ã€‚[/]"
    )
    conversation_history = []

    try:
        while True:
            try:
                question = prompt("\n>> ", multiline=False).strip()
                if not question:
                    continue

                if question.lower() == "@new":
                    conversation_history.clear()
                    console.clear()
                    console.print("\nğŸŒŸ [cyan]ä¸Šä¸‹æ–‡å·²é‡ç½®ï¼Œå¼€å¯æ–°å¯¹è¯[/]")
                    continue

                console.print("\nğŸ¤” [yellow]æ­£åœ¨æ·±åº¦æ€è€ƒ...[/]")

                analysis, think_time = get_think_process(conversation_history, question)

                console.print(f"\n{dynamic_separator('æ€è€ƒè¿‡ç¨‹åˆ†æ')}\n")
                render_stream_markdown(analysis)
                console.print(f"\nğŸ” [dim]æ·±åº¦æ€è€ƒè€—æ—¶: {format_time(think_time)}[/]")

                console.print(f"\n{dynamic_separator('æœ€ç»ˆç­”æ¡ˆç”Ÿæˆ')}\n")
                answer_buffer = []
                start_time = time.time()
                full_content = ""

                try:
                    for chunk in stream_final_answer(
                        conversation_history, analysis, question
                    ):
                        full_content += chunk
                        answer_buffer.append(chunk)

                    render_stream_markdown(full_content)

                except Exception as e:
                    if full_content:
                        render_stream_markdown(full_content)
                    console.print(f"\nâš ï¸ [red]ç”Ÿæˆä¸­æ–­: {str(e)}[/]")
                finally:
                    if full_content:
                        conversation_history.extend(
                            [
                                {"role": "user", "content": question},
                                {"role": "assistant", "content": full_content},
                            ]
                        )

                    total_time = time.time() - start_time
                    console.print("\n" + "=" * console.width)
                    console.print(
                        f"âœ… [green]ç”Ÿæˆå®Œæˆ[/] | [dim]è€—æ—¶: {format_time(total_time)}[/] | "
                        f"[dim]ä¸Šä¸‹æ–‡é•¿åº¦: {len(conversation_history)//2}è½®[/]"
                    )

            except KeyboardInterrupt:
                console.print(
                    "\nğŸ›‘ [red]æ“ä½œå·²å–æ¶ˆï¼Œåœ¨ 1s å†…å†æ¬¡æŒ‰ä¸‹ Ctrl+C é€€å‡ºç¨‹åº[/]"
                )
                time.sleep(1)

    except KeyboardInterrupt:
        console.print("\nğŸ‘‹ å†è§ï¼")
        exit()
    except Exception as e:
        console.print(f"\nâŒ [red]å¤„ç†é”™è¯¯: {str(e)}[/]")
        conversation_history.clear()
